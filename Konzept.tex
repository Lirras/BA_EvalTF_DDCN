\documentclass[ngerman]{report}

\title{Evaluierung von Transferlernen mit Deep Direct Cascade Networks}

\author{Simon Tarras}

\begin{document}
    \maketitle
    \chapter{Einführung}
        \section{Cascade Networks}
        Kaskadennetzwerke sind so aufgebaut, dass sie während sie 
        im Training sind wachsen und nur die neu hinzugekommenen 
        Sachen traininert werden.
        \section{Transferlernen}
        Transferlernen ist, wenn ein Neuronales Netzwerk von der 
        einen Sache vorlernt, um eine andere Sache besser zu 
        bearbeiten.
    \chapter{Klassifikation}
    Eine Klassifikation ist dann, wenn ein NN eingegebene Daten zu 
    eindeutigen Klassen zuordnen soll.
    Ausführung auf GPU klappt zurzeit nicht. Warum?
    Wieso ist nach dem ersten Linearlayer die Accuracy über 8000\%?
    Scheinbar kann man nicht damit anfangen.
    Wie kann ich es machen, dass es schneller geht bei mehreren Epochen 
    und einem großen Netz? -> Auf GPU geht ja nicht.
    Abspeichern zwischen den einzelnen Layern, damit die Trainingsphase 
    schneller wird, muss mit Tensoren passieren, die nicht in einer Liste 
    stehen. 
    Target Layer muss 3-Dimensional sein, wenn die Batch-Size größer als 1 
    ist und auch wenn ein multi-Class-Loss wie Negative Log-Likelihood-Loss 
    genutzt wird. Wie bekommt man das hin?
    \chapter{Regression}
    Bei einer Regression kommt es dazu, dass das NN sich mithilfe 
    der Daten der korrekten Funktion annähert.
\end{document}