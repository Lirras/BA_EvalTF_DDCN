In diesem Kapitel werden zentrale Eigenschaften analysiert, die sowohl bei Klassifikations- als auch bei Regressionsaufgaben auftreten und 
unabhängig vom zugrunde liegenden Cascade-Learning-Ansatz – sei es Deep Cascade oder Direct Cascade – beobachtet werden konnten.

Zunächst wird die Interpretation der dargestellten Plots erläutert, um ein einheitliches Verständnis der Visualisierungen zu gewährleisten. 
Anschließend werden zwei besonders auffällige, konsistent auftretende Phänomene diskutiert: der signifikante Leistungseinbruch unmittelbar 
nach Anwendung von Transfer Learning sowie das ausgeprägte Overfitting auf dem Quelldatensatz.

Abschließend wird die Trainingsdauer der eingesetzten Netzwerkarchitekturen analysiert. Dabei zeigt sich, dass der Einfluss von Transfer 
Learning auf die Trainingszeit bei kleinen Datensätzen von den in der Literatur beschriebenen Ergebnissen abweicht.
