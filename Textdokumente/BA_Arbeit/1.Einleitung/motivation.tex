Es gibt Aufgaben, die gerne von einer KI übernommen werden sollen, für die es nur sehr kleine Datensätze gibt. Diese sind so klein, dass das 
neuronale Netzwerk hinter der KI nicht genügend Daten für das Training hat, um ein ausreichend gutes und belastbares Ergebnis zu liefern. 
Es ist dabei auch egal, wie lange trainiert wird; es bleibt schlecht. 

Gleichzeitig gibt es den Punkt, dass es meistens ziemlich lange dauert ein Netzwerk komplett zu trainieren. Beides soll verbessert werden. 

Die Situation mit den zu wenig Daten wird darüber versucht zu verbessern, indem etwas anderes, aber ähnliches, gelernt wird. Dies folgt dem 
Prinzip, wie die Menschen andere ähnliche Dinge lernen können, wenn sie das Eine bereits können. Ebenso verlaufen Eselsbrücken für Menschen 
einem ähnlichem Prinzip. Diese Art des Lernens, die über bereits Bekanntes etwas neues lernt, soll nun auch für KI angewandt werden. 

Die Trainingsdaten werden so reduziert, dass das, was tatsächlich im selbem Augenblick trainiert wird, nur sehr wenig ist. Dies soll über die 
Kaskadierungsverfahren Deep Cascade und Direct Cascade gehen. 
