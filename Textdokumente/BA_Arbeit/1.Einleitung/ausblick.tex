In dem Kapitel 2 wird Kaskadierung, Transferlernen, das genutzte Rechensystem, die Early-Stopping Metriken, die Datensätze und alle 
relevanten Tests vorgestellt.

In Kapitel 3 werden die konsistent Taskübergreifenden auftretenden Dinge behandelt. Im genaueren ist es der Performanzabfall direkt bei TF, 
das Overfitting auf dem Sourcedatensatz. Dafür wird ein Deep Cascade Klassifikationsnetzwerk genutzt. 
Ebenso werden hier die Vergleiche der Trainingsdauer aller Netze durchgeführt und dessen Ergebnis erläutert. 

In Kapitel 4 werden nur die Erkenntnisse, die spezifisch bei der Klassifikation auftauchen, behandelt. Diese sind die Veränderung der 
Targetdatenmenge, die Erstellung der Augmented Vectors und die Vergleiche zwischen den Netzstrukturen bei denselben genutzten Layern, um 
herauszufinden, wieso Klassifikation nicht mit Cascade TF funktioniert. 

In Kapitel 5 werden die Regressionsspezifische Beobachtungen erläutert. Dazu werden viele und wenige Targetdaten mit dem Vergleich zwischen 
Cascade TF, Cascade und Komplettnetzen genutzt. Dabei fällt auf, dass es mitunter mit TF besser ist als ohne. Da es hier generell auch dazu 
kommt, dass Cascade TF funktioniert, werden hier auch Early-Stopping Metriken betrachtet. 

Und in Kapitel 6 ist eine kurze Zusammenfassung aller Erkenntnisse und ein Ausblick, was in diesem Thema noch vertiefend betrachtet werden kann. 
