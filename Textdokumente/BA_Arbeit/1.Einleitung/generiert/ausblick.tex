Kapitel 2 enthält eine Einführung in die grundlegenden Konzepte dieser Arbeit. Es werden die Kaskadierungsverfahren, das Prinzip des 
TFs, das verwendete Rechensystem, die eingesetzten Early-Stopping-Metriken sowie die für das Training verwendeten Datensätze 
vorgestellt. Darüber hinaus erfolgt eine Übersicht über alle durchgeführten Tests einschließlich ihrer jeweiligen Kennungen und Zielsetzungen.

Kapitel 3 widmet sich den systematisch auftretenden Phänomenen beim domänenübergreifenden TF. Im Fokus stehen hierbei der 
Leistungsabfall unmittelbar nach dem Transfer sowie das Overfitting auf den Source-Datensatz. Zur Analyse wird ein 
Deep-Cascade-Klassifikationsnetzwerk eingesetzt. Zudem werden in diesem Kapitel die Trainingszeiten aller betrachteten Netzarchitekturen 
verglichen und die Ergebnisse interpretiert.

Kapitel 4 behandelt ausschließlich beobachtete Effekte, die spezifisch im Kontext der Klassifikationsaufgabe auftreten. Dazu zählen die 
Auswirkungen unterschiedlicher Target-Datenmengen, die Erstellung sogenannter Augmented Vectors sowie der Vergleich 
unterschiedlicher Netzarchitekturen bei identischer Layer-Konfiguration. Ziel ist es, zu klären, warum TF im Rahmen von 
Kaskadie-rung bei Klassifikationsaufgaben nicht zuverlässig funktioniert.

Kapitel 5 fokussiert sich auf regressionsspezifische Beobachtungen. Hierfür werden sowohl Szenarien mit großen als auch mit kleinen Target-Datenmengen 
untersucht, wobei ein Vergleich zwischen Cascade TF, klassischer Kaskadierung und vollständig trainierten Netzwerken erfolgt. 
Dabei zeigt sich, dass TF in be-stimmten Konstellationen zu besseren Ergebnissen führt. Da in diesem Kontext Cascade TF 
funktional einsetzbar ist, werden hier zusätzlich die Auswirkungen verschiedener Early-Stopping-Metriken betrachtet.

Kapitel 6 bietet eine zusammenfassende Darstellung der zentralen Erkennt-nisse dieser Arbeit sowie einen Ausblick auf potenzielle weiterführende 
For-schungsfragen in diesem Themenfeld.
