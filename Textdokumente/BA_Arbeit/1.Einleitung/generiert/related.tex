Diese Arbeit basiert auf dem Cascade-Correlation-Algorithmus (CasCor) \cite{cascor}, der ursprünglich entwickelt wurde, um der hohen 
Trainingsdauer klassischer neuronaler Netze entgegenzuwirken. Aufbauend auf diesem Verfahren wird die Methode Direct Cascade implementiert, 
wie sie unter anderem in der Dissertation von Marquez \cite{phd_deep_cascade} beschrieben ist und auf Ansätzen aus 
\cite{cascade_network_architectures} beruht. Als Vergleichsmodell dient das Verfahren Deep Cascade \cite{deep_cascade_learning}, bei dem 
Netzwerke schrittweise und iterativ erweitert werden \cite{Constructive_Cascade}.

Im Rahmen dieser Arbeit wird ausschließlich der Domänenwechsel betrachtet, während der Aufgabenwechsel (Task Transfer) \cite{transfer_learning} 
unberücksichtigt bleibt. Darüber hinaus werden drei zentrale Herausforderungen des Transferlernens behandelt, wie sie in \cite{survey_transfer} 
identifiziert wurden. \\
