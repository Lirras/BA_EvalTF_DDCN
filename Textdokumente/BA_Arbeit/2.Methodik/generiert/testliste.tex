Von den betrachteten Netzwerken sind ConvMaxPool und RegressionTwo Deep Cascade Netzwerke, während alle weiteren Modelle als 
Direct Cascade Netzwerke klassifiziert werden. Zudem handelt es sich bei RegressionTwo und OneLayer um Regressionsnetzwerke, während die übrigen 
Modelle Klassifikationsnetzwerke darstellen.

Alle Netzwerke wurden mit dem Adam-Optimierer bei einer Lernrate von $1*10^{-3}$ trainiert. Für die Klassifikationsnetzwerke wurde die 
Verlustfunktion Categorical Cross-Entropy verwendet, kombiniert mit einer Softmax-Aktivierungsfunktion im Ausgangs-Layer. Die 
Regressionsnetzwerke hingegen verwenden Mean Squared Error (MSE) als Verlustfunktion und eine lineare Aktivierungsfunktion.

Zusätzlich wurden bei allen Direct Cascade Netzwerken Early-Stopping-Kriterien basierend auf den Metriken MAEM, 
LM und ACCM angewandt.

Für die Klassifikationsnetzwerke erfolgte das Training mit fünf unterschiedlichen Größen des Target-Datensatzes. Eine 
Ausnahme bildet das 2DC-Netzwerk, das aufgrund technischer Einschränkungen der verwendeten Hardware nur mit sehr kleinen Mengen von Source- 
und Target-Daten trainiert werden kann.

Bei den Regressionsnetzwerken wurde jeweils ein Training mit großer sowie mit kleiner Menge an Target-Daten durchgeführt.

Darüber hinaus wurden mit allen Netzwerken Vergleiche zwischen Trainingsläufen mit TF und ohne sowie zwischen Trainings 
ohne TF und sogenannten vollständigen Netzwerken durchgeführt. Ein vollständiges Netzwerk bezeichnet hierbei ein Modell, das ohne TF 
und ohne Kaskadierung in einem einzigen vollständigen Training trainiert wird. Dies ist das klassische Training neuronaler Netzwerke. 

Der Zeitpunkt des Einsatzes von TF wurde für alle Netzwerke experimentell frei gewählt.

Alle Direct Cascade Netzwerke verfügen jeweils über genau einen Hidden Layer. In einigen Fällen wird zusätzlich ein Hilfslayer verwendet, um 
den Übergang zwischen Filter-Layern (Convolutional Layer) und linearen Layern zu ermöglichen.

Für alle Experimente wurde derselbe Initialisierungs-Seed für die Gewichtungen verwendet, um Reproduzierbarkeit sicherzustellen.

Die Ergebnisse der Klassifikationstests sind in Tabelle \ref{tab:classtests} zusammengefasst, die Regressionstests in Tabelle \ref{tab:regrtests}. 
In beiden Tabellen sind Tests, die sich auf die Trainingsdauer beziehen, mit dem Suffix "Time" gekennzeichnet. Dabei steht CasTF für Kaskadierung 
mit TF, Cas für Kaskadierung ohne TF und Comp für Trainings ohne Kaskadierung und ohne TF - 
also den sogenannten vollständigen Netzen. 

Die Bezeichnungen vor dem ersten Schrägstrich geben den Zeitpunkt des TF an, wobei dies mit "TF" explizit markiert ist. Fehlt dieser 
Eintrag, wurde kein TF durchgeführt. Anschließend folgt die Datenmenge des Target-Datensatzes sowie die Anzahl der Epochen pro 
Trainingsiteration. Optional enthält die Bezeichnung eine weitere Angabe, die die Gesamtanzahl der Epochen in Zehner-Schritten angibt.

\begin{table}[!ht]
    \centering
    \begin{tabular}{l|l|l|l}
        \textbf{CMP} & \textbf{COD} & \textbf{1DC} & \textbf{2DC} \\
        \hline
        TF0/732/10 & CasTFTime & CasTFTime & CasTFTime \\
        TF1/732/10 & CasTime & CasTime & CasTime \\
        TF2/732/10 & CompTime & CompTime & CompTime \\
        TF3/732/10 & TF2/732/10 & TF2/732/10 & TF2/732/10 \\
        TF4/732/10 & TF2/7k/10 & TF2/7k/10 & \\
        TF5/732/10 & TF2/21k/10 & TF2/21k/10 & \\
        732/10 & TF2/36k/10 & TF2/36k/10 & \\
        CasTFTime & TF2/51k/10 & TF2/51k/10 & \\
        CasTime & TF10/732/10/30 & TF10/732/10/30 & \\
        CompTime & 732/10/30 & 732/10/30 & \\
        TF2/7k/10 & Comp/732//30 & Comp/732//30 & \\
        TF2/21k/10 & ACCM/732/10 & ACCM/732/10 & \\
        TF2/36k/10 & LM/732/10 & LM/732/10 & \\
        TF2/51k/10 & & & \\
        & & & \\
    \end{tabular}
    \caption{\label{tab:classtests} Liste aller Klassifikationstests}
\end{table}

\begin{table}[!ht]
    \centering
    \begin{tabular}{l|l}
        \textbf{Regr2} & \textbf{1Lay} \\
        \hline
        TF0/240/25 & CasTFTime \\
        TF1/240/25 & CasTime \\
        TF4/240/25 & CompTime \\
        CasTFTime & TF11/8k/10/21 \\
        CasTime & 8k/10/11 \\
        CompTime & Comp/8k//8 \\
        TF4/8k/10/8 & TF11/240/10/21 \\
        8k/10/8 & 240/10/11 \\
        Comp/8k//8 & Comp/240//8 \\
        TF4/240/10/8 & MAEM/240/10 \\
        240/10/8 & LM/240/10 \\
        Comp/240//8 & TF4/206/10/8/ts \\
        TF4/206/10/8/ts & 206/10/8/ts \\
        206/10/8/ts & Comp/206//8/ts \\
        Comp/206//8/ts &
    \end{tabular}
    \caption{\label{tab:regrtests} Liste aller Regressionstests}
\end{table}

Ein Beispiel für eine Referenz auf einen spezifischen Testeintrag ist CMP:TF0/732/10. Diese Kennzeichnung verweist auf den Test des 
CMP-Netzwerks mit TF, das unmittelbar nach dem ersten Layer erfolgt. In diesem speziellen Fall wird das erste Layer 
lediglich über eine einzige Epoche trainiert, während alle weiteren Layer nach dem üblichen Trainingsschema optimiert werden. Das gleiche 
Vorgehen gilt für den Test Regr2:TF0/240/25, bei dem analog das erste Layer nur eine Epoche lang trainiert wird.

Testeinträge mit dem Suffix "ts" kennzeichnen solche Experimente, bei denen ein gezielt großer Testdatensatz verwendet wurde.

Die Tests mit unterschiedlichen TF-Layern dienen dazu, den sinnvollen Einsatz von TF zu evaluieren. Alle Tests mit dem Zusatz "Time" verfolgen 
das Ziel, die Trainingsdauer zu vergleichen. Die Untersuchungen mit variierenden Target-Datenmengen analysieren das Verhalten 
von TF bei unterschiedlichen Datenvolumina sowie die generelle Leistungsfähigkeit der Netzwerke. Tests mit einer erhöhten Anzahl an 
Gesamtepochen und tieferer Netzstruktur ermöglichen eine detaillierte Betrachtung des Einflusses von TF auf tiefe Netze. Die Versuche, bei denen 
verschiedene Metriken zum Einsatz kommen, prüfen, inwiefern diese Early-Stopping-Metriken zu einer Leistungsverbesserung führen. Schließlich 
dienen die Tests mit umfangreichen Testdatensätzen der Überprüfung der Generalisierungsfähigkeit der Netzwerke und der Validierung bisheriger 
Erkenntnisse.
